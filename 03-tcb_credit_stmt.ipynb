{
  "metadata": {
    "kernelspec": {
      "display_name": "Jupyter Notebook",
      "name": "jupyter"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "eb15dd59-6f78-4d97-beba-287313687c44",
      "cell_type": "code",
      "metadata": {
        "resultVariableName": "dataframe_3",
        "language": "sql",
        "name": "set_db_schema",
        "title": "set_db_schema"
      },
      "source": "%%sql -r dataframe_3\nUSE SCHEMA RAW_DB.PDF;\nUSE WAREHOUSE COMPUTE_WH;",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "1381147f-6af5-4aab-8a33-85c53d7f0b2c",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "# Processing TCB credit statement (pdf files)\n* Method: AI_PARSE_DOCUMENT\n* Stage for this has been created in 02-historical_parse script\n* Upload done prior to running this script\n\n",
      "execution_count": null
    },
    {
      "id": "592eb956-01e1-4d9e-bc5c-9ec07beec0e0",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "import_packages",
        "title": "import_packages"
      },
      "source": "# Import python packages\n# import streamlit as st\nimport pandas as pd\n\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import Session\n\nimport snowflake.connector\nimport re\nimport time\n\n\nsession = get_active_session()\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "75341b25-6a61-44f5-9c72-a50540335bf3",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "setup_var",
        "title": "setup_var"
      },
      "source": "CREDIT_STAGE = 'TCB_CREDIT_STAGE'\nDATABASE = 'RAW_DB'\nSCHEMA = 'PDF'",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3ae5e1f2-8782-4e09-b790-590470db4c2a",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "file_list",
        "title": "file_list"
      },
      "source": "file_list = session.sql(f\"\"\"\n    select distinct\n        metadata$filename as file_name,\n        metadata$file_last_modified as file_last_modified,\n        'TCB_CREDIT_' || split(file_name, '_')[1]::string as table_name\n    from @\"{DATABASE}\".\"{SCHEMA}\".\"{CREDIT_STAGE}\"\n    \"\"\"\n    ).to_pandas()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6c185512-91e5-4d20-aca6-49dc1b5e5cde",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "parse_into_tables",
        "title": "parse_into_tables"
      },
      "source": "for _,row in file_list.iterrows():\n    file_name = row['FILE_NAME']\n    table_name = row['TABLE_NAME']\n\n    print(f'Processing {file_name} into {table_name}')\n    parse_query = f\"\"\"\n        create or replace table {DATABASE}.{SCHEMA}.{table_name} as (\n        SELECT AI_PARSE_DOCUMENT (\n            TO_FILE('@\"{DATABASE}\".\"{SCHEMA}\".\"{CREDIT_STAGE}\"','{file_name}'),\n            {{'mode': 'LAYOUT', 'page_split': true}}) AS content);\n            \"\"\"\n    session.sql(parse_query).collect()\n\nprint(\"Completed loading images to tables\")\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "48c58f8c-54db-4ad9-8824-873ff3cca954",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "union_query",
        "title": "union_query"
      },
      "source": "process_count = 0\ntotal_files = len(file_list)\nprint(total_files)\nquery = \"\"\n\n\nfor _,row in file_list.iterrows():\n    file_name = row['FILE_NAME']\n    table_name = row['TABLE_NAME']\n    \n    process_count +=1\n    if process_count < total_files:\n        query += f\"\"\"\n            select '{table_name}' as file_source, content::string as content\n            from {DATABASE}.{SCHEMA}.{table_name} union all  --{process_count}\n        \"\"\"\n    else:\n        query += f\"\"\"\n            select '{table_name}' as file_source, content::string as content\n            from {DATABASE}.{SCHEMA}.{table_name}  --{process_count}\n        \"\"\"\n\nprint(query)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "90de95fc-a0b5-4d15-aae3-fc1cb269c233",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "union_execute",
        "title": "union_execute"
      },
      "source": "session.sql(f\"\"\"\n    create or replace table TRANSFORM_DB.BASE.UNIONED_TCB_CREDIT as \n    (with unioned as ({query})\n    \n     select \n            file_source,\n            try_parse_json(content) as content\n        \n            from unioned)\n\"\"\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6a0e82b0-7f4e-4519-9b8d-2ccf8f09ea34",
      "cell_type": "code",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "name": "transform_df",
        "title": "transform_df"
      },
      "source": "transform_df = session.sql(f\"\"\"\nwith flattened as (\n    select \n        file_source,\n        p.index + 1 as page,    \n        p.value['content']::string as page_content_text,\n        pt.index,\n        pt.value,\n        row_number() over(order by file_source, p.index, pt.index) as seq\n    from TRANSFORM_DB.BASE.UNIONED_TCB_CREDIT,\n    lateral flatten(input => content['pages']) as p,\n    lateral split_to_table(page_content_text,'|') as pt\n    order by file_source, page, seq\n),\nanchors as (\n    select \n        file_source,\n        case \n            when file_source = 'TCB_CREDIT_20250520' and value like '%Ghi nợ%' then seq \n            when file_source != 'TCB_CREDIT_20250520' and value like '%Diễn giải%' then seq\n        else null end\n        as anchor_index\n    from flattened\n    where anchor_index is not null\n)\n, data_rows as (\n    select\n        t.*,\n        t.seq - a.anchor_index - 9 as offset_from_anchor\n    from flattened t\n    join anchors a \n        on t.seq >= a.anchor_index + 9 --has to be seq, not index\n        and t.file_source = a.file_source\n        \n)\n        \n, numbered as (\n    select\n        file_source,\n        page,\n        page_content_text,\n        index,\n        value,\n        seq,\n        offset_from_anchor,\n        case \n            -- special case\n            when file_source = 'TCB_CREDIT_20250520' and page = 1 and mod(offset_from_anchor, 6) = 4 then 5\n            when file_source = 'TCB_CREDIT_20250520' and page = 1 and mod(offset_from_anchor, 6) = 5 then 6\n            when file_source = 'TCB_CREDIT_20250520' and page = 1 then mod(offset_from_anchor, 6)\n            when file_source = 'TCB_CREDIT_20250520' and page = 2 and mod(index - 1, 6) < 5 then mod(index - 1, 6) - 1 \n            when file_source = 'TCB_CREDIT_20250520' and page = 2 and mod(index - 1, 6) >= 5 then mod(index - 1, 6)\n            --else\n            when file_source != 'TCB_CREDIT_20250520' and page = 1 then mod(offset_from_anchor, 7) \n            when file_source != 'TCB_CREDIT_20250520' and page = 2 and mod(index - 1, 6) < 5 then mod(index - 1, 6) - 1 \n            when file_source != 'TCB_CREDIT_20250520' and page = 2 and mod(index - 1, 6) >= 5 then mod(index - 1, 6)\n        end \n            as col_pos, \n        row_number() over(partition by file_source, page, col_pos order by index) as record_num        \n    from data_rows\n    order by seq\n)\n\n, pivoted as (\nselect\n    file_source,\n    page,\n    record_num,\n    max(case when col_pos = 0 then value end) as transaction_date_tmp,\n    max(case when col_pos = 1 then value end) as post_date_tmp,\n    max(case when col_pos = 2 then value end) as original_amount_tmp,\n    max(case when col_pos = 3 then value end) as debit_tmp,\n    max(case when col_pos = 4 then value end) as credit_tmp,\n    max(case when col_pos = 5 then value end) as description\n    --ignore col 6\nfrom numbered\ngroup by all\norder by 1,2,3\n)\n-- , final_result as (\nselect \n    file_source,\n    page,\n    record_num,\n    -- transaction_date_tmp,\n    interpolate_bfill(\n        try_to_date(transaction_date_tmp, 'dd/mm/yyyy')) \n        over(partition by file_source, page order by record_num desc) as transaction_date,\n    try_to_date(post_date_tmp, 'dd/mm/yyyy') as post_date,\n    \n    try_cast(replace(\n        split(original_amount_tmp, ' ')[1]::string,\n        ',','') as decimal(18,2))\n        as original_amount,\n    split(original_amount_tmp, ' ')[2]::string as original_curr,\n    coalesce(case when description ilike '%the tin dung%' or description ilike '%merchandi%return%' or description ilike '%tindung%' or description ilike '%tín dụng%'then 0\n        else try_cast(replace(debit_tmp, ',', '') as decimal(18,2)) end,0) as debit,\n    coalesce(case when description ilike '%the tin dung%' or description ilike '%merchandi%return%' or description ilike '%tindung%' or description ilike '%tín dụng%'then \n        coalesce(try_cast(replace(credit_tmp, ',', '') as decimal(18,2)), original_amount)\n        else try_cast(replace(credit_tmp, ',', '') as decimal(18,2)) end,0) as credit,\n    description\nfrom pivoted \nwhere post_date is not null\norder by 1,2,3\n\"\"\").to_pandas()",
      "execution_count": null
    },
    {
      "id": "12b7fa93-3783-4533-88bc-013ddfa24f3f",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "write_table",
        "title": "write_table"
      },
      "source": "session.write_pandas(\n    df=transform_df,\n    database='TRANSFORM_DB',\n    schema='INT',\n    table_name='HISTORY_TCB_CREDIT',\n    overwrite=True,\n    auto_create_table=True\n)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "db4d1163-c6e9-4ad9-9b9f-68b25d41351b",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "show_mismatch_result",
        "title": "show_mismatch_result"
      },
      "source": "test_df = session.sql('''\n    with test as (\n        select \n            f.file_source,\n            try_cast(replace(f.paper_debit, ',','') as decimal(18,2)) as debit,\n            try_cast(replace(f.paper_credit, ',','') as decimal(18,2)) as credit,\n            sum(fr.debit) as sql_debit, \n            sum(fr.credit) as sql_credit,\n        from raw_db.audit_files.tcb_credit_balance as f\n        left join transform_db.int.history_tcb_credit as fr using (file_source)\n        group by all\n        order by 1\n        )\nselect * ,\n    debit - sql_debit as diff_dr,\n    credit - sql_credit as diff_cr\nfrom test\nwhere diff_dr !=0 or diff_cr != 0\n\n'''\n).collect()\n\ntest_df",
      "outputs": [],
      "execution_count": null
    }
  ]
}