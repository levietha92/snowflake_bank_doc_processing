{
  "metadata": {
    "kernelspec": {
      "display_name": "Streamlit Notebook",
      "name": "streamlit"
    },
    "lastEditStatus": {
      "notebookId": "ngfl75ms6zzvarpdqtwx",
      "authorId": "",
      "authorName": "",
      "sessionId": "64cef90e-5473-4563-a13a-e743ea7384bc",
      "lastEditTime": 0
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "36e6654b-a4f4-41cf-af78-8a5970282187",
      "metadata": {
        "name": "intro",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "# PDF extraction from JPEG files\n- Method: Process all JPEG files in stage using AI_PARSE_DOCUMENT\n- Steps:\n1. Load jpeg files into respective stages\n2. AI_PARSE_DOCUMENT on jpeg files in each stage, output as table of `content` parsed\n3. Union all into 1 table\n4. Transform parsed `content` into respective VIB and TCB tables, preserving original tabular structure in images\n5. Test output\n\n\n"
    },
    {
      "cell_type": "code",
      "id": "3775908f-ca36-4846-8f38-5adca39217f2",
      "metadata": {
        "language": "python",
        "name": "import_packages"
      },
      "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import Session\n\nimport snowflake.connector\nimport re\nimport time\n\n\nsession = get_active_session()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "dc32b557-be7d-45c3-b908-eaa1da44542f",
      "metadata": {
        "language": "python",
        "name": "setup_var"
      },
      "outputs": [],
      "source": "DATABASE='RAW_DB'\nSCHEMA='PDF'\nTABLE_NAME='HISTORY_FILE_LIST'\nTCB_STAGE='TCB_HISTORY_STAGE'\nVIB_STAGE='VIB_HISTORY_STAGE'\nCREDIT_STAGE='TCB_CREDIT_STAGE'\n\nTRANSFORM_DB = 'TRANSFORM_DB'\nTRANSFORM_BASE = 'TRANSFORM_DB.BASE'\nTRANSFORM_INT = 'TRANSFORM_DB.INT'\nTRANSFORM_MART = 'TRANSFORM_DB.MART'\nUNION_TABLE = 'UNIONED_HISTORICAL_PDF'\n\nFRESH_START = False #if set to true it will run the setup_stages block\nREDO = False # reset this to False if you already processed AI_PARSE_DOCUMENT\n\n#comment this out if no redo items\nREDO_LIST = [ \n    # 'VIB_IMG_5282',\n    # 'VIB_IMG_5283',\n    # 'VIB_IMG_5285',\n    # 'VIB_IMG_5286',\n    # 'VIB_IMG_5290',\n    # 'VIB_IMG_5291',\n    # 'VIB_IMG_5300',\n    # 'VIB_IMG_5302',\n    # 'VIB_IMG_5303',\n    # 'VIB_IMG_5304',\n    # 'VIB_IMG_5306',\n    # 'TCB_IMG_5111',\n    # 'TCB_IMG_5080'\n    # 'VIB_IMG_5284',\n    # 'VIB_IMG_5288',\n    # 'VIB_IMG_5289',\n    # 'VIB_IMG_5294',\n    # 'VIB_IMG_5296',\n    # 'VIB_IMG_5299'\n    # 'TCB_IMG_5072',\n    'TCB_IMG_5114','TCB_IMG_5116'\n    ] \n",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "0505fda3-f182-4c98-ba0e-1b099db67662",
      "metadata": {
        "language": "python",
        "name": "setup_objects"
      },
      "outputs": [],
      "source": "if FRESH_START:\n    session.sql(f'''\n        CREATE DATABASE {DATABASE};\n        CREATE SCHEMA {DATABASE}.{SCHEMA};\n        create or replace database {TRANSFORM_DB};\n        create or replace schema {TRANSFORM_BASE};\n        create or replace schema {TRANSFORM_INT};\n        create or replace schema {TRANSFORM_MART};\n    ''')\n    print(f'Setting up {DATABASE}.{SCHEMA} completed')\n    \n    session.sql(f'''\n        ALTER ACCOUNT SET CORTEX_ENABLED_CROSS_REGION = 'ANY_REGION';\n        \n        -- Server-side encryption (supported)\n        CREATE OR REPLACE STAGE {DATABASE}.{SCHEMA}.{TCB_STAGE}\n          ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE')\n          DIRECTORY = ( ENABLE = TRUE ); \n        \n        CREATE OR REPLACE STAGE {DATABASE}.{SCHEMA}.{VIB_STAGE}\n          ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE')\n          DIRECTORY = ( ENABLE = TRUE ); \n        \n        CREATE OR REPLACE STAGE {DATABASE}.{SCHEMA}.{CREDIT_STAGE}\n          ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE')\n          DIRECTORY = ( ENABLE = TRUE );\n    '''\n    )\n    print('Setting up stages completed. Go ahead and load files into stages')\nelse:\n    print('No setup required')",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "898d97f1-76fc-46a0-a99c-6ec6d857536e",
      "metadata": {
        "language": "python",
        "name": "create_file_list"
      },
      "outputs": [],
      "source": "# Create the DataFrame first\nfile_list = session.sql(f'''\n    SELECT distinct\n        metadata$filename as file_name,\n        metadata$file_last_modified as file_last_modified,\n        '{VIB_STAGE}' as from_where,\n        'VIB_' || split_part(file_name, '.',1) as table_name\n    FROM @\"{DATABASE}\".\"{SCHEMA}\".\"{VIB_STAGE}\"\n    union all\n    SELECT distinct\n        metadata$filename as file_name,\n        metadata$file_last_modified as file_last_modified,\n        '{TCB_STAGE}' as from_where,\n        'TCB_' || split_part(file_name, '.',1) as table_name\n    FROM @\"{DATABASE}\".\"{SCHEMA}\".\"{TCB_STAGE}\"\n''').to_pandas()\n\nif file_list is None:\n    # Then write to table\n    session.write_pandas(\n        df=file_list,\n        database=DATABASE,\n        schema=SCHEMA,\n        table_name=TABLE_NAME,\n        auto_create_table=True,\n        overwrite=True\n    )\nelse:\n    print('Already got file_list')",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "39f370d2-bf5c-4c7d-8312-0190b1d813d9",
      "metadata": {
        "name": "step2_md",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Step 2: Parse everything into tables"
    },
    {
      "cell_type": "code",
      "id": "d64c97e5-b25d-448b-a439-3f83c152648b",
      "metadata": {
        "language": "python",
        "name": "parse_all",
        "collapsed": false,
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "if session.sql('''\n    select count(*) as record from raw_db.information_schema.tables\n    where \n        table_name like 'TCB%' \n        or table_name like 'VIB%'\n    ''').to_pandas()['RECORD'][0] == 0 or REDO:\n    for _,row in file_list.iterrows():\n        file_name = row['FILE_NAME']\n        table_name = row['TABLE_NAME']\n        stage_name = row['FROM_WHERE']\n        print(f'Processing {file_name} into {table_name}')\n        parse_query = f\"\"\"\n            create or replace table {DATABASE}.{SCHEMA}.{table_name} as (\n            SELECT AI_PARSE_DOCUMENT (\n                TO_FILE('@\"{DATABASE}\".\"{SCHEMA}\".\"{stage_name}\"','{file_name}'),\n                {{'mode': 'LAYOUT', 'page_split': false}}) AS content);\n                \"\"\"\n        session.sql(parse_query).collect()\n    \n    print(\"Completed loading images to tables\")\nelse:\n    print('Already parsed historical images last time')",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "846a36ca-8f00-40c1-8656-edf3832d0966",
      "metadata": {
        "language": "python",
        "name": "parse_redo_only"
      },
      "outputs": [],
      "source": "if REDO_LIST is not None:\n    for file in REDO_LIST:\n        stage_name = file.split('_',1)[0] + '_HISTORY_STAGE'\n        file_name = file.split('_',1)[1] + '.jpeg'\n        table_name = file\n        \n        print(f'Processing {file_name} into {table_name}')\n        \n        parse_query = session.sql(f\"\"\"\n            SELECT AI_PARSE_DOCUMENT (\n                TO_FILE('@\"{DATABASE}\".\"{SCHEMA}\".\"{stage_name}\"','{file_name}'),\n                {{'mode': 'LAYOUT', 'page_split': false}})::object AS content\n                \"\"\").to_pandas()\n\n        session.write_pandas(\n            df=parse_query,\n            database=DATABASE,\n            schema=SCHEMA,\n            table_name=table_name,\n            overwrite=True\n        )\n\n    print(\"Completed loading images to tables\")",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "65dc2bd7-32d5-4b65-93fe-0a4b0edbeb4c",
      "metadata": {
        "name": "step3_md",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Step 3: Union all contents into 1 table"
    },
    {
      "cell_type": "code",
      "id": "62d109e2-82d4-4d1f-8b7d-dad5ff523b2c",
      "metadata": {
        "language": "python",
        "name": "union_to_one",
        "collapsed": false,
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "process_count = 0\ntotal_files = len(file_list)\nprint(total_files)\nquery = \"\"\n\n\nfor _,row in file_list.iterrows():\n    file_name = row['FILE_NAME']\n    table_name = row['TABLE_NAME']\n    \n    process_count +=1\n    if process_count < total_files:\n        query += f\"\"\"\n            select '{table_name}' as file_source, content::string as content\n            from {DATABASE}.{SCHEMA}.{table_name} union all  --{process_count}\n        \"\"\"\n    else:\n        query += f\"\"\"\n            select '{table_name}' as file_source, content::string as content\n            from {DATABASE}.{SCHEMA}.{table_name}  --{process_count}\n        \"\"\"\n\nprint(query)\n",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "d92bc80c-88d4-4988-aff4-a0a05e1438b3",
      "metadata": {
        "language": "python",
        "name": "unioned_history"
      },
      "outputs": [],
      "source": "session.sql(f\"\"\"\n    create or replace table {TRANSFORM_INT}.{UNION_TABLE} as \n    (with unioned as ({query})\n    \n     select \n            file_source,\n            try_parse_json(content) as content\n        \n            from unioned)\n\"\"\")",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "1f35ba91-bec0-4ad6-b1d4-b2f51f0070e5",
      "metadata": {
        "language": "sql",
        "name": "check_result_unioned",
        "resultVariableName": "dataframe_3"
      },
      "outputs": [],
      "source": "%%sql -r dataframe_3\n-- select top 10 * from TRANSFORM_DB.BASE.UNIONED_HISTORICAL_PDF where file_source = 'VIB_IMG_5282';\n-- select top 10 * from TRANSFORM_DB.BASE.UNIONED_HISTORICAL_PDF where file_source = 'TCB_IMG_5080';\nselect count(*) from TRANSFORM_DB.BASE.UNIONED_HISTORICAL_PDF ;",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "cc6021e1-8515-47a1-9281-0e3c4dfd9047",
      "metadata": {
        "name": "create_tcb_md",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Step 3: Create TCB table out of PDFs"
    },
    {
      "cell_type": "code",
      "id": "f376490e-5340-4061-968c-f3ce2bd2837b",
      "metadata": {
        "language": "python",
        "name": "create_tcb",
        "resultVariableName": "dataframe_4",
        "collapsed": true,
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "tcb_df = session.sql(f'''\nwith joined as (\n    select *,\n        'TCB' as from_where\n    from TRANSFORM_DB.BASE.UNIONED_HISTORICAL_PDF  \n    where file_source like 'TCB%'\n),\ncleansed as (\n    select\n        from_where,\n        file_source,\n        index,\n        mod(index - 1, 11) as position_in_group,\n        value,\n        row_number() over(partition by file_source, position_in_group order by index) as record_group\n    from joined,\n    lateral split_to_table(content['content']::string,'|')\n    order by file_source,index \n),\ntransformed_data AS (\n    SELECT \n        file_source,\n        record_group,\n        MAX(CASE WHEN position_in_group = 1 THEN trim(value) END) AS transaction_date,\n        MAX(CASE WHEN position_in_group = 2 THEN trim(value) END) AS remitter,\n        MAX(CASE WHEN position_in_group = 3 THEN trim(value) END) AS remitter_bank,\n        MAX(CASE WHEN position_in_group = 4 THEN trim(value) END) AS details,\n        MAX(CASE WHEN position_in_group = 5 THEN trim(value) END) AS transaction_no,\n        MAX(CASE WHEN position_in_group = 6 THEN trim(value) END) AS debit,\n        MAX(CASE WHEN position_in_group = 7 THEN trim(value) END) AS credit,\n        MAX(CASE WHEN position_in_group = 8 THEN trim(value) END) AS fee_interest,\n        MAX(CASE WHEN position_in_group = 9 THEN trim(value) END) AS tax,\n        MAX(CASE WHEN position_in_group = 10 THEN trim(value) END) AS balance_tmp\n    from cleansed\n    group by all\n    \n)\n\nselect \n    file_source,\n    try_to_date(transaction_date, 'dd/mm/yyyy') AS transaction_date,\n    remitter,\n    remitter_bank,\n    details,\n    transaction_no,\n    TRY_CAST(REPLACE(debit, ',', '') AS DECIMAL(18,2)) AS debit,\n    TRY_CAST(REPLACE(credit, ',', '') AS DECIMAL(18,2)) AS credit,\n    TRY_CAST(REPLACE(fee_interest, ',', '') AS DECIMAL(18,2)) AS fee_interest,\n    TRY_CAST(REPLACE(tax, ',', '') AS DECIMAL(18,2)) AS tax,\n    TRY_CAST(REPLACE(balance_tmp, ',', '') AS DECIMAL(18,2)) AS balance,\n    row_number() over(order by file_source,record_group) AS record_sequence\nfrom transformed_data\nwhere balance is not null\norder by file_source, record_group \n\n''').to_pandas()\n\nsession.write_pandas(\n    df=tcb_df,\n    database='TRANSFORM_DB',\n    schema='INT',\n    table_name='HISTORY_TCB_BS',\n    auto_create_table=True,\n    overwrite=True\n)",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "73501abf-1ef5-4a53-872e-d21e3cbb71ad",
      "metadata": {
        "name": "create_vib_md",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Step 4: Create VIB table out of PDFs"
    },
    {
      "cell_type": "code",
      "id": "aa6adbfe-68b1-46a2-8249-5136b47ad552",
      "metadata": {
        "language": "python",
        "name": "create_vib",
        "collapsed": true,
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "vib_df = session.sql(f'''\nwith joined as (\n    select *,\n        'VIB' as from_where\n    from TRANSFORM_DB.BASE.UNIONED_HISTORICAL_PDF\n    where file_source like 'VIB%'\n),\ncleansed as (\n    select\n        from_where,\n        file_source,\n        index,\n        mod(index - 1, 10) as position_in_group,\n        value,\n        row_number() over(partition by file_source, position_in_group order by index) as record_group\n    from joined,\n    lateral split_to_table(content['content']::string,'|')\n    -- having position_in_group > 0\n    order by file_source,index \n)\n-- select * from cleansed;\n,transformed_data AS (\n    SELECT \n        file_source,\n        record_group,\n        MAX(CASE WHEN position_in_group = 1 THEN trim(value) END) AS seq_no,\n        MAX(CASE WHEN position_in_group = 2 THEN trim(value) END) AS transaction_date,\n        MAX(CASE WHEN position_in_group = 3 THEN trim(value) END) AS effective_date,\n        MAX(CASE WHEN position_in_group = 4 THEN trim(value) END) AS transaction_type,\n        MAX(CASE WHEN position_in_group = 5 THEN trim(value) END) AS cheque_ref,\n        MAX(CASE WHEN position_in_group = 6 THEN trim(value) END) AS debit,\n        MAX(CASE WHEN position_in_group = 7 THEN trim(value) END) AS credit,\n        MAX(CASE WHEN position_in_group = 8 THEN trim(value) END) AS balance,\n        MAX(CASE WHEN position_in_group = 9 THEN trim(value) END) AS description,\n    from cleansed\n    group by all\n    \n)\n-- select * from transformed_data order by file_source, record_group ;\n, casting as (\nselect \n    file_source,\n    record_group,\n    row_number() over(order by record_group) AS record_sequence,\n    try_to_decimal(seq_no) as seq_no, --removed the TK doi ung texts\n    try_to_date(transaction_date, 'dd/mm/yyyy') AS transaction_date,\n    try_to_date(effective_date, 'dd/mm/yyyy') AS effective_date,\n    case when len(transaction_type) = 0 then null else transaction_type end as transaction_type,\n    case when len(description) = 0 then null else description end as description,\n    TRY_CAST(REPLACE(debit, ',', '') AS DECIMAL(18,2)) AS debit,\n    TRY_CAST(REPLACE(credit, ',', '') AS DECIMAL(18,2)) AS credit,\n    TRY_CAST(REPLACE(balance, ',', '') AS DECIMAL(18,2)) AS balance,\n    \nfrom transformed_data\n-- where len(seq_no) = 10 \norder by file_source, record_group\n)\n-- select * from casting;\n\n, ffill as (\nselect\n    file_source,\n    record_group,\n    record_sequence,\n    interpolate_ffill(seq_no) over(partition by file_source order by record_group) as seq_no,\n    interpolate_ffill(transaction_date) over(partition by file_source order by record_group)  as transaction_date,\n    interpolate_ffill(effective_date) over(partition by file_source order by record_group)  as effective_date,\n    interpolate_ffill(transaction_type) over(partition by file_source order by record_group)  as transaction_type,\n    description,\n    interpolate_ffill(debit) over(partition by file_source order by record_group)  as debit,\n    interpolate_ffill(credit) over(partition by file_source order by record_group)  as credit,\n    interpolate_ffill(balance) over(partition by file_source order by record_group)  as balance,\n    \nfrom casting \norder by file_source, seq_no \n)\n-- select * from ffill;\nselect\n    file_source,\n    listagg(record_group, ',') as record_group_agg,\n    listagg(record_sequence, ',') as record_sequence_agg,\n    seq_no,\n    transaction_date,\n    effective_date,\n    transaction_type,\n    listagg(description, ' ') as description,\n    debit,\n    credit,\n    balance\n    \nfrom ffill\nwhere balance is not null --good filter condition, only lost last page 5306 which doesn't contain extra info anw\ngroup by all\norder by file_source, seq_no\n\n''').to_pandas()\n\nsession.write_pandas(\n    df=vib_df,\n    database='TRANSFORM_DB',\n    schema='INT',\n    table_name='HISTORY_VIB_BS',\n    auto_create_table=True,\n    overwrite=True\n)",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "7470f5a4-0575-49fa-ac17-f5487f7ee401",
      "metadata": {
        "name": "step5_md",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Step 5: Check Result"
    },
    {
      "cell_type": "code",
      "id": "e2a459ee-94d6-4515-a83c-e80b7223f261",
      "metadata": {
        "language": "python",
        "name": "check_file_count"
      },
      "outputs": [],
      "source": "fc_dest = session.sql(f'''\n    select '{VIB_STAGE}' as from_where, count(distinct file_source) as file_count \n    from TRANSFORM_DB.INT.HISTORY_VIB_BS\n    union all\n    select '{TCB_STAGE}' as from_where, count(distinct file_source) as file_count \n    from TRANSFORM_DB.INT.HISTORY_TCB_BS\n''').to_pandas()\nfc_dest\n\nfc_target = file_list.groupby('FROM_WHERE').count().reindex()\nfc_target\n\nfc_dest[fc_dest['FROM_WHERE'] == VIB_STAGE]['FILE_COUNT'].iloc[0] == fc_target['FILE_NAME'].iloc[1]\nprint(f\"{VIB_STAGE} is {fc_target['FILE_NAME'].iloc[1]}\")\n\nfc_dest[fc_dest['FROM_WHERE'] == TCB_STAGE]['FILE_COUNT'].iloc[0] == fc_target['FILE_NAME'].iloc[0]\nprint(f\"{TCB_STAGE} is {fc_target['FILE_NAME'].iloc[0]}\")",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "24d64070-ede2-4bc4-97e9-3c76fbcaf45e",
      "metadata": {
        "language": "python",
        "name": "check_row_count"
      },
      "outputs": [],
      "source": "fc_dest = session.sql(f'''\n    select distinct file_source::string as file_source, count(*) as row_count \n    from TRANSFORM_DB.INT.HISTORY_VIB_BS\n    group by all\n    union all\n    select distinct file_source::string as file_source, count(*) as row_count \n    from TRANSFORM_DB.INT.HISTORY_TCB_BS\n    group by all\n''').to_df(['file_source','row_count'])\n# fc_dest\n\nfc_target = session.sql(f'''\n        select file_source::string as file_source,\n            manual_row_count\n        from {DATABASE}.AUDIT_FILES.HISTORY_MANUAL_ROW_COUNT\n        '''\n).to_df(['file_source','manual_row_count'])\n# fc_target\n\n\nfrom snowflake.snowpark import functions as F\ncheck_rc = fc_target.join(fc_dest, on='file_source', how='left', lsuffix='target', rsuffix='dest').sort('file_source')\ncheck_rc = check_rc.withColumn('diff', F.lit(check_rc['manual_row_count'] - check_rc['row_count'])) \n# check_rc\n\nsession.write_pandas(check_rc.to_pandas(),database=TRANSFORM_DB,schema='AUDIT_FILES',table_name='CHECK_ROW_COUNT_HISTORY_BS',auto_create_table=True, overwrite=True)\n",
      "execution_count": null
    }
  ]
}